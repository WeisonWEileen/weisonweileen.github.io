---
permalink: /
title: "Wei Pan (潘炜) "
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a third-year undergraduate student at Southern University of Science and Technology (SUSTech), majoring in Robotics Engineering, where I work closely with  <a href="https://scholar.google.com.hk/citations?user=-fnyGY4AAAAJ&hl=en">Prof. Boyu Zhou</a>, <a href="https://scholar.google.com/citations?hl=en&user=HQ6j-KsAAAAJ&view_op=list_works&sortby=pubdate">Prof. Wei Zhang</a>, and <a href="https://scholar.google.com/citations?hl=zh-CN&user=hejSEsYAAAAJ&view_op=list_works&sortby=pubdate">Prof. Chenglong Fu</a> .
Fansinated by the combination of Robotics in AI, I am eager to focus my future reaserach on **(a) Robotics with generative model and 3D perception**, **(b) Co-designing powerful model training paradigm and efficient on-board deployment.**

Research
======



<div style="display: flex; align-items: flex-start;margin-bottom: 60px;">
    <video width="420" height="200" autoplay loop muted>
        <source src="/images/manipulation.mp4" type="video/mp4">
    </video>
    <div style="margin-left: 10px;">
        <b>
            Generative Visual Foresight Meets Task-Agnostic Pose Estimation in Robotic Table-top Manipulation 
        </b>
        <br>
        <!-- <strong style="color: green;"><i>under review</i></strong> &nbsp;&nbsp;&nbsp;&nbsp; -->
        <p>
            <span>&bull; utilized Rectified Flow for efficient video generation</span>
            <br>
            <span>&bull; proposed transformer based RGB-D only input for end effector pose estimation using Vision Transformer</span>
        </p>
    </div>
</div>


<div style="display: flex; align-items: flex-start; margin-bottom: 60px;">
    <a  style="height: 14em;" class="research-thumb">
        <img src="/images/glass.png" width="360" height="160" alt="Research Image">
    </a>
    <div style="margin-left: 10px;">
        <b>
               UAV Perception and Navigation
        </b>
        <br>
        <!-- <strong style="color: green;"><i>todos</i></strong> &nbsp;&nbsp;&nbsp;&nbsp; -->
        <p>
            <span>&bull; inference in the air </span>
            <!-- <span>&bull; Utilzing diffusion model to improve the perception ability of UAV </span>
            <br>
            <span>&bull; Efficient Deployment of diffusion model</span> -->
        </p>
    </div>
</div>


<div style="display: flex; align-items: flex-start; margin-bottom: 40px;">
    <a  style="height: 14em;" class="research-thumb">
        <img src="/images/centaur.gif" width="400" height="245" alt="Research Image">
    </a>
    <div style="margin-left: 10px;">
        <b>Centaur Robot for Load-carriage Walking Assistance
        </b>
        <p>
        <!-- <strong style="color: green;"><i>todos</i></strong> &nbsp;&nbsp;&nbsp;&nbsp; -->
        <br>
        <span>&bull; reinforcement learning based control strategy </span>
        <br>
        <span>&bull; multi-terrain and multi-loading adaption </span>
        <br>
        </p>
    </div>
</div>


<div style="display: flex; align-items: flex-start; margin-bottom: 40px;">
    <a  style="height: 14em;" class="research-thumb">
        <img src="/images/reha.png" width="980" height="625" alt="Research Image">
    </a>
    <div style="margin-left: 10px;">
        <b>Flexible Multi-Channel Electrical Stimulation System for Assisting Grasping in Patients with Hemiplegia
        </b>
        <p>
        <!-- <br> -->
        <span>J. Sun, G. Huang, C. Lin, <b>W, Pan</b>, K. H. Cheng, G. Gou.,  in 2024 International Conference on Advanced Robotics and Mechatronics (ICARM), 2024
</span>
        <br>
        <a href="/files/paper1.pdf">Paper</a>&nbsp;&nbsp;&nbsp;&nbsp;
        </p>
    </div>
</div>



<div style="display: flex; align-items: flex-start; margin-bottom: 40px;">
    <a  style="height: 14em;" class="research-thumb">
        <img src="/images/reha2.png" width="980" height="625" alt="Research Image">
    </a>
    <div style="margin-left: 10px;">
        <b>IMU-Based Prediction of Multiple Grasping Gesture Intentions for
Enhanced Functional Electrical Stimulation Control
Competition
        </b>
        <p>
        <!-- <br> -->
        <span>G. Gou, K. H. Cheng, J. Sun, C. Lin,
<b>W. Pan</b>, G Huang,  in 2024 International Conference on Advanced Robotics and Mechatronics (ICARM), 2024
</span>
        <br>
        <a href="/files/paper2.pdf">Paper</a>&nbsp;&nbsp;&nbsp;&nbsp;
        </p>
    </div>
</div>


Competition
======
<div style="display: flex; align-items: flex-start; margin-bottom: 60px;">
    <!-- <a  style="height: 14em;" class="research-thumb">
        <img src="/images/robocon.png" width="1180" height="675" alt="Research Image">
    </a> -->
    <video width="420" height="200" autoplay loop muted>
        <source src="/images/robot.mp4" type="video/mp4">
    </video>
    <div style="margin-left: 10px;">
        <b><i>Robocon 2024 National Robocon National University Robotics Competition</i>
        </b>
        <br>
        <strong style="color: purple;"><i>National First Prize, National Second Prize</i></strong> &nbsp;&nbsp;&nbsp;&nbsp;
        <p>
        <b>group algorithm leader</b>, implementationof object detection, localization and inference optimization.
        <span>
</span>
        <br>
        </p>
    </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 40px;">
    <a  style="height: 14em;" class="research-thumb">
        <img src="/images/fpga.gif" width="1480" height="1375" alt="Research Image">
    </a>
    <div style="margin-left: 10px;">
        <b><i>National FPGA and Embedded System Competition</i>
        </b>
        <br>
        <strong style="color: purple;"><i>National Second Prize</i></strong> &nbsp;&nbsp;&nbsp;&nbsp;
        <p>a high-performance ionic electronic skin perception system on
Xilinx ZYQN 7020, achieve <b>2000 Hz</b> sensing frequency, a real-time master machine software visualization using Qt framework
        <span>
        <br>
        <a href="https://github.com/WeisonWEileen/pyqt-touching-show">Code</a>&nbsp;&nbsp;&nbsp;&nbsp;
</span>
        <br>
        </p>
    </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 40px;">
    <a  style="height: 14em;" class="research-thumb">
        <img src="/images/qtdifraction.png" width="1380" height="775" alt="Research Image">
    </a>
    <div style="margin-left: 10px;">
        <b><i>National University Physics Experiment Software Design Competition </i>
        </b>
        <br>
        <strong style="color: purple;">National Second Prize</strong> &nbsp;&nbsp;&nbsp;&nbsp;
        <p>Developed two-dimensional diffraction simulation software based on mobile phone screen grating
experiment; uilized Qt framework design UI and realize 3D model interaction
        <a href="https://github.com/Jupiter2143/QtDiffractionSimulator?tab=readme-ov-file">Code</a>&nbsp;&nbsp;&nbsp;&nbsp;
        <br>
        </p>
    </div>
</div>



Projects Hightlights
====
<div style="display: flex; align-items: flex-start; margin-bottom: 40px;">
    <a  style="height: 14em;" class="research-thumb">
        <img src="/images/onnx.png" width="580" height="375" alt="Research Image">
    </a>
    <div style="margin-left: 10px;">
        <b><i>Depth-Anything v2 Onnx Runtime implementation</i>
        </b>
        <br>
        <p>Implemtated Depth-Anythingv2 Large model for onnxruntime acceleration.
        <br>
        <a href="https://github.com/WeisonWEileen/depthanythingv2-onnxruntime-cpp-inference">Code</a>&nbsp;&nbsp;&nbsp;&nbsp;
        <br>
        </p>
    </div>
</div>


<div style="display: flex; align-items: flex-start; margin-bottom: 40px;">
    <a  style="height: 14em;" class="research-thumb">
        <img src="/images/dbscan.png" width="780" height="475" alt="Research Image">
    </a>
    <div style="margin-left: 10px;">
        <b>Pointcloud Clustering
        </b>
        <br>
        <p>Implenmentated DBscan Algorithm for pointcloud clustering based on cartesian coordinates
        <br>
        </p>
    </div>
</div>
